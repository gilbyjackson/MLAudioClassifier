{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f9fdd5",
   "metadata": {},
   "source": [
    "# MFCC Feature Extractor \n",
    "\n",
    "This is stage 1 of the Method 1 pipeline, so this should be the first notebook you run after unzipping the data archives. \n",
    "\n",
    "**Updated to support 6 instrument classes**: Crash, Hihat, Kick, Ride, Snare, Tom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfa7a95f-5b29-4c34-a37b-bbc6bc6a1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from math import log, pi, exp, ceil\n",
    "import statistics as st\n",
    "import pandas as pd\n",
    "import scipy.io as io\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "354a3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please set this variable to where you cloned the git repo \"MLAudioClassifier\"\n",
    "\n",
    "filepath = \"/Users/Gilby/Projects/MLAudioClassifier\"\n",
    "os.chdir(filepath)\n",
    "\n",
    "# make sure you have extracted the Training and Testing Data before you proceed with the rest of the notebook\n",
    "# with something like \"unzip TrainingData.zip\"\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caed6611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reset to project directory: /Users/Gilby/Projects/MLAudioClassifier\n",
      "✅ Found TrainingData/\n",
      "✅ Found TestData/\n",
      "Ready to proceed!\n"
     ]
    }
   ],
   "source": [
    "# Reset to project root directory (run this if you get lost in subdirectories)\n",
    "filepath = \"/Users/Gilby/Projects/MLAudioClassifier\"\n",
    "os.chdir(filepath)\n",
    "print(f\"✅ Reset to project directory: {os.getcwd()}\")\n",
    "\n",
    "# Verify we can see the expected directories\n",
    "expected_dirs = [\"TrainingData\", \"TestData\"]\n",
    "for directory in expected_dirs:\n",
    "    if os.path.exists(directory):\n",
    "        print(f\"✅ Found {directory}/\")\n",
    "    else:\n",
    "        print(f\"❌ Missing {directory}/\")\n",
    "        \n",
    "print(\"Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55792a",
   "metadata": {},
   "source": [
    "# Loading training data \n",
    "\n",
    "This block of code will load in each audio file of the training data set and calculate it's MFCCs for all 6 instrument classes (Crash, Hihat, Kick, Ride, Snare, Tom). Please note that there will be a lot of warnings in red after you run this cell, but they are just warnings and the code is still running fine without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "897b3fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking directory structure...\n",
      "Current directory: /Users/Gilby/Projects/MLAudioClassifier\n",
      "✅ Found TrainingData/AudioSamples\n",
      "   Training classes: ['Kick', 'Rim', 'Splash', 'Tom', 'Shaker', 'Bongo', 'Conga', 'Maracas', 'Metal', 'Hihat', 'Snare', 'Perc', 'FX', 'Ride', 'Agogo', 'Triangle', 'Whistle', 'Crash', 'Reverse', 'China', 'Tambourine', 'Vox', 'Noise', 'Clap', 'Woodblock', 'Clave', 'Bell', 'Cowbell', 'Cabasa', 'Vibraslap', 'Guiro', 'Timpani', 'Cuica', 'Timbale']\n",
      "   Kick: 1540 samples\n",
      "   Rim: 224 samples\n",
      "   Splash: 33 samples\n",
      "   Tom: 1985 samples\n",
      "   Shaker: 66 samples\n",
      "   Bongo: 168 samples\n",
      "   Conga: 351 samples\n",
      "   Maracas: 55 samples\n",
      "   Metal: 26 samples\n",
      "   Hihat: 524 samples\n",
      "   Snare: 2409 samples\n",
      "   Perc: 483 samples\n",
      "   FX: 1595 samples\n",
      "   Ride: 370 samples\n",
      "   Agogo: 53 samples\n",
      "   Triangle: 59 samples\n",
      "   Whistle: 43 samples\n",
      "   Crash: 203 samples\n",
      "   Reverse: 76 samples\n",
      "   China: 42 samples\n",
      "   Tambourine: 61 samples\n",
      "   Vox: 101 samples\n",
      "   Noise: 90 samples\n",
      "   Clap: 392 samples\n",
      "   Woodblock: 38 samples\n",
      "   Clave: 49 samples\n",
      "   Bell: 225 samples\n",
      "   Cowbell: 138 samples\n",
      "   Cabasa: 49 samples\n",
      "   Vibraslap: 13 samples\n",
      "   Guiro: 55 samples\n",
      "   Timpani: 25 samples\n",
      "   Cuica: 42 samples\n",
      "   Timbale: 76 samples\n",
      "✅ Found TestData\n",
      "   Test classes: ['Kick', 'Rim', 'Tom', 'Hihat', 'Snare', 'Ride', 'Crash', 'Clap', 'Bell', 'Cowbell']\n",
      "   Kick: 124 samples\n",
      "   Rim: 34 samples\n",
      "   Tom: 362 samples\n",
      "   Hihat: 242 samples\n",
      "   Snare: 124 samples\n",
      "   Ride: 224 samples\n",
      "   Crash: 313 samples\n",
      "   Clap: 71 samples\n",
      "   Bell: 14 samples\n",
      "   Cowbell: 24 samples\n",
      "\n",
      "Ready to process audio files!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify directory structure before processing\n",
    "# First, ensure we're in the correct project directory\n",
    "os.chdir(filepath)\n",
    "print(\"Checking directory structure...\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check training data\n",
    "train_path = \"TrainingData/AudioSamples\"\n",
    "if os.path.exists(train_path):\n",
    "    print(f\"✅ Found {train_path}\")\n",
    "    train_folders = [f for f in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, f)) and not f.startswith('.')]\n",
    "    print(f\"   Training classes: {train_folders}\")\n",
    "    for folder in train_folders:\n",
    "        wav_count = len(glob.glob(os.path.join(train_path, folder, \"*.wav\")))\n",
    "        print(f\"   {folder}: {wav_count} samples\")\n",
    "else:\n",
    "    print(f\"❌ {train_path} not found!\")\n",
    "\n",
    "# Check test data  \n",
    "test_path = \"TestData\"\n",
    "if os.path.exists(test_path):\n",
    "    print(f\"✅ Found {test_path}\")\n",
    "    test_folders = [f for f in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, f)) and not f.startswith('.')]\n",
    "    print(f\"   Test classes: {test_folders}\")\n",
    "    for folder in test_folders:\n",
    "        wav_count = len(glob.glob(os.path.join(test_path, folder, \"*.wav\")))\n",
    "        print(f\"   {folder}: {wav_count} samples\")\n",
    "else:\n",
    "    print(f\"❌ {test_path} not found!\")\n",
    "\n",
    "print(\"\\nReady to process audio files!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd85484d-d4b4-4738-97c2-4753d82d09fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from: /Users/Gilby/Projects/MLAudioClassifier\n",
      "Processing Kick samples...\n",
      "  Found 1540 files\n",
      "Processing Rim samples...\n",
      "  Found 224 files\n",
      "Processing Splash samples...\n",
      "  Found 33 files\n",
      "Processing Tom samples...\n",
      "  Found 1985 files\n",
      "Processing Shaker samples...\n",
      "  Found 66 files\n",
      "Processing Bongo samples...\n",
      "  Found 168 files\n",
      "Processing Conga samples...\n",
      "  Found 351 files\n",
      "Processing Maracas samples...\n",
      "  Found 55 files\n",
      "Processing Metal samples...\n",
      "  Found 26 files\n",
      "Processing Hihat samples...\n",
      "  Found 524 files\n",
      "Processing Snare samples...\n",
      "  Found 2409 files\n",
      "Processing Perc samples...\n",
      "  Found 483 files\n",
      "Processing FX samples...\n",
      "  Found 1595 files\n",
      "Processing Ride samples...\n",
      "  Found 370 files\n",
      "Processing Agogo samples...\n",
      "  Found 53 files\n",
      "Processing Triangle samples...\n",
      "  Found 59 files\n",
      "Processing Whistle samples...\n",
      "  Found 43 files\n",
      "Processing Crash samples...\n",
      "  Found 203 files\n",
      "Processing Reverse samples...\n",
      "  Found 76 files\n",
      "Processing China samples...\n",
      "  Found 42 files\n",
      "Processing Tambourine samples...\n",
      "  Found 61 files\n",
      "Processing Vox samples...\n",
      "  Found 101 files\n",
      "Processing Noise samples...\n",
      "  Found 90 files\n",
      "Processing Clap samples...\n",
      "  Found 392 files\n",
      "Processing Woodblock samples...\n",
      "  Found 38 files\n",
      "Processing Clave samples...\n",
      "  Found 49 files\n",
      "Processing Bell samples...\n",
      "  Found 225 files\n",
      "Processing Cowbell samples...\n",
      "  Found 138 files\n",
      "Processing Cabasa samples...\n",
      "  Found 49 files\n",
      "Processing Vibraslap samples...\n",
      "  Found 13 files\n",
      "Processing Guiro samples...\n",
      "  Found 55 files\n",
      "Processing Timpani samples...\n",
      "  Found 25 files\n",
      "Processing Cuica samples...\n",
      "  Found 42 files\n",
      "Processing Timbale samples...\n",
      "  Found 76 files\n",
      "Training data extraction complete!\n",
      "Total samples: 11659\n",
      "Class distribution: {np.int64(0): np.int64(1540), np.int64(1): np.int64(224), np.int64(2): np.int64(33), np.int64(3): np.int64(1985), np.int64(4): np.int64(66), np.int64(5): np.int64(168), np.int64(6): np.int64(351), np.int64(7): np.int64(55), np.int64(8): np.int64(26), np.int64(9): np.int64(524), np.int64(10): np.int64(2409), np.int64(11): np.int64(483), np.int64(12): np.int64(1595), np.int64(13): np.int64(370), np.int64(14): np.int64(53), np.int64(15): np.int64(59), np.int64(16): np.int64(43), np.int64(17): np.int64(203), np.int64(18): np.int64(76), np.int64(19): np.int64(42), np.int64(20): np.int64(61), np.int64(21): np.int64(101), np.int64(22): np.int64(90), np.int64(23): np.int64(392), np.int64(24): np.int64(38), np.int64(25): np.int64(49), np.int64(26): np.int64(225), np.int64(27): np.int64(138), np.int64(28): np.int64(49), np.int64(29): np.int64(13), np.int64(30): np.int64(55), np.int64(31): np.int64(25), np.int64(32): np.int64(42), np.int64(33): np.int64(76)}\n"
     ]
    }
   ],
   "source": [
    "# Ensure we're in the project root directory first\n",
    "os.chdir(filepath)\n",
    "print(f\"Starting from: {os.getcwd()}\")\n",
    "\n",
    "os.chdir(\"TrainingData/AudioSamples\")\n",
    "folder_names = glob.glob(\"*\")\n",
    "# Filter out hidden files and directories\n",
    "folder_names = [f for f in folder_names if not f.startswith('.') and os.path.isdir(f)]\n",
    "all_samples = { 'label':[], 'mfcc':[] }\n",
    "i=0\n",
    "frames_max = 0\n",
    "for instrument in folder_names:\n",
    "    print(f\"Processing {instrument} samples...\")\n",
    "    os.chdir(instrument)\n",
    "    file_names = glob.glob(\"*.wav\")\n",
    "    print(f\"  Found {len(file_names)} files\")\n",
    "    for wav in file_names:\n",
    "        waveform, samplerate = librosa.load(wav, sr=44100, mono=True)\n",
    "        waveform = librosa.util.fix_length(waveform, size=50000)\n",
    "        # Fixed: Added y= parameter for newer librosa versions\n",
    "        mfcc = librosa.feature.mfcc(y=waveform, sr=samplerate, n_mfcc=40, n_fft=2048, hop_length=512)\n",
    "        normalized_mfcc = librosa.util.normalize(mfcc)\n",
    "        all_samples['mfcc'].append(normalized_mfcc.tolist())\n",
    "        all_samples['label'].append(i)\n",
    "        # Update frames maximum\n",
    "        #if (num_frames > frames_max):\n",
    "            #frames_max = num_frames\n",
    "    os.chdir(\"..\")\n",
    "    i=i+1\n",
    "os.chdir(filepath)\n",
    "\n",
    "print(f\"Training data extraction complete!\")\n",
    "print(f\"Total samples: {len(all_samples['label'])}\")\n",
    "print(f\"Class distribution: {dict(zip(*np.unique(all_samples['label'], return_counts=True)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751cd3f3",
   "metadata": {},
   "source": [
    "<h1> Loading testing data </h1>\n",
    "<p> This block of code will load in each audio file of the testing data set and calculate it's MFCCs. Please note that there will be a lot of warnings in red after you run this cell, but they are just warnings and the code is still running fine without errors. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7d3ae95-40c5-469f-949d-fb784193c5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Kick test samples...\n",
      "  Found 124 files\n",
      "Processing Rim test samples...\n",
      "  Found 34 files\n",
      "Processing Tom test samples...\n",
      "  Found 362 files\n",
      "Processing Hihat test samples...\n",
      "  Found 242 files\n",
      "Processing Snare test samples...\n",
      "  Found 124 files\n",
      "Processing Ride test samples...\n",
      "  Found 224 files\n",
      "Processing Crash test samples...\n",
      "  Found 313 files\n",
      "Processing Clap test samples...\n",
      "  Found 71 files\n",
      "Processing Bell test samples...\n",
      "  Found 14 files\n",
      "Processing Cowbell test samples...\n",
      "  Found 24 files\n",
      "Test data extraction complete!\n",
      "Total test samples: 1532\n",
      "Test class distribution: {np.int64(0): np.int64(124), np.int64(1): np.int64(34), np.int64(2): np.int64(362), np.int64(3): np.int64(242), np.int64(4): np.int64(124), np.int64(5): np.int64(224), np.int64(6): np.int64(313), np.int64(7): np.int64(71), np.int64(8): np.int64(14), np.int64(9): np.int64(24)}\n"
     ]
    }
   ],
   "source": [
    "os.chdir(filepath)\n",
    "os.chdir(\"TestData\")  # Fixed: removed the extra /TestData\n",
    "folder_names = glob.glob(\"*\")\n",
    "# Filter out hidden files and directories\n",
    "folder_names = [f for f in folder_names if not f.startswith('.') and os.path.isdir(f)]\n",
    "test_samples = { 'label':[], 'mfcc':[] }\n",
    "i=0\n",
    "frames_max = 0\n",
    "for instrument in folder_names:\n",
    "    print(f\"Processing {instrument} test samples...\")\n",
    "    os.chdir(instrument)\n",
    "    file_names = glob.glob(\"*.wav\")\n",
    "    print(f\"  Found {len(file_names)} files\")\n",
    "    for wav in file_names:\n",
    "        waveform, samplerate = librosa.load(wav, sr=44100, mono=True)\n",
    "        waveform = librosa.util.fix_length(waveform, size=50000)\n",
    "        # Fixed: Added y= parameter for newer librosa versions\n",
    "        mfcc = librosa.feature.mfcc(y=waveform, sr=samplerate, n_mfcc=40, n_fft=2048, hop_length=512)\n",
    "        normalized_mfcc = librosa.util.normalize(mfcc)\n",
    "        test_samples['mfcc'].append(normalized_mfcc.tolist())\n",
    "        test_samples['label'].append(i)\n",
    "        # Update frames maximum\n",
    "        #if (num_frames > frames_max):\n",
    "            #frames_max = num_frames\n",
    "    os.chdir(\"..\")\n",
    "    i=i+1\n",
    "os.chdir(\"..\")\n",
    "\n",
    "print(f\"Test data extraction complete!\")\n",
    "print(f\"Total test samples: {len(test_samples['label'])}\")\n",
    "print(f\"Test class distribution: {dict(zip(*np.unique(test_samples['label'], return_counts=True)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b779a-403b-4758-a1be-2a251b7c78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(filepath)\n",
    "json_path='data/mfcc_train_data.json'\n",
    "with open(json_path, \"w\") as fp:\n",
    "        json.dump(all_samples, fp, indent=4)\n",
    "        \n",
    "json_path2='dat/mfcc_test_data.json'\n",
    "with open(json_path2, \"w\") as fp2:\n",
    "        json.dump(test_samples, fp2, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
