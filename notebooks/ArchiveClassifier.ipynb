{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724abc6a",
   "metadata": {},
   "source": [
    "# Drum Sample Auto-Classifier - Complete Archive Edition\n",
    "\n",
    "This notebook demonstrates how to use the trained model to automatically classify and organize drum samples from your complete drum archive, while keeping the original archive read-only.\n",
    "\n",
    "## Key Features\n",
    "- **Read-only source**: Works with your `/complete_drum_archive` without modifying it\n",
    "- **Copy-based processing**: Creates copies for classification, preserving originals\n",
    "- **Repeatable**: Can be run multiple times without affecting source data\n",
    "- **Selective processing**: Can target specific folders or file patterns\n",
    "\n",
    "## Prerequisites\n",
    "1. **Train a model first** by running these notebooks in order:\n",
    "   - `MFCC_Feature_Extractor.ipynb` (extracts features from sorted training data)\n",
    "   - `Model1_Train.ipynb` or `Model2_Train.ipynb` (trains the classifier)\n",
    "\n",
    "2. **Set up your archive path**:\n",
    "   - Point to your `/complete_drum_archive` directory\n",
    "   - The notebook will create a separate output directory for results\n",
    "\n",
    "## Configuration Options\n",
    "- **Source directory**: Your complete drum archive (read-only)\n",
    "- **Output directory**: Where classified copies will be placed\n",
    "- **Processing mode**: Copy vs. symbolic links vs. move\n",
    "- **File filtering**: By extension, size, or pattern\n",
    "\n",
    "## How it works\n",
    "- Scans your complete drum archive (without modifying it)\n",
    "- Creates organized copies in a separate output directory\n",
    "- Classifies each sample with confidence scoring\n",
    "- Organizes results by instrument type\n",
    "- Preserves original file structure in output naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "033fed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import keras\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d42db15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning archive: /Users/Gilby/Projects/MLAudioClassifier/complete_drum_archive\n",
      "Found 0 .wav files\n",
      "Found 0 .aiff files\n",
      "Found 0 .flac files\n",
      "Found 0 .mp3 files\n",
      "Total audio files found: 0\n",
      "\u274c No audio files found in archive!\n",
      "Checked formats: ['.wav', '.aiff', '.flac', '.mp3']\n",
      "In directory: /Users/Gilby/Projects/MLAudioClassifier/complete_drum_archive\n"
     ]
    }
   ],
   "source": [
    "# Scan Archive and Find Audio Files\n",
    "# ===================================\n",
    "\n",
    "def find_audio_files(archive_path, formats=SUPPORTED_FORMATS, max_files=MAX_FILES_PER_RUN):\n",
    "    \"\"\"Recursively find all audio files in the archive\"\"\"\n",
    "    audio_files = []\n",
    "    \n",
    "    print(f\"Scanning archive: {archive_path}\")\n",
    "    archive_path = Path(archive_path)\n",
    "    \n",
    "    for format_ext in formats:\n",
    "        pattern = f\"**/*{format_ext}\"\n",
    "        files = list(archive_path.glob(pattern))\n",
    "        audio_files.extend(files)\n",
    "        print(f\"Found {len(files)} {format_ext} files\")\n",
    "    \n",
    "    print(f\"Total audio files found: {len(audio_files)}\")\n",
    "    \n",
    "    if max_files and len(audio_files) > max_files:\n",
    "        print(f\"Limiting to first {max_files} files for this run\")\n",
    "        audio_files = audio_files[:max_files]\n",
    "    \n",
    "    return audio_files\n",
    "\n",
    "# Scan the archive\n",
    "audio_files = find_audio_files(ARCHIVE_PATH)\n",
    "\n",
    "if not audio_files:\n",
    "    print(\"\u274c No audio files found in archive!\")\n",
    "    print(f\"Checked formats: {SUPPORTED_FORMATS}\")\n",
    "    print(f\"In directory: {ARCHIVE_PATH}\")\n",
    "else:\n",
    "    print(f\"\u2705 Ready to process {len(audio_files)} audio files\")\n",
    "    print(f\"Sample files:\")\n",
    "    for i, file in enumerate(audio_files[:5]):  # Show first 5\n",
    "        print(f\"  {i+1}. {file.name}\")\n",
    "    if len(audio_files) > 5:\n",
    "        print(f\"  ... and {len(audio_files) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0b4f6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Classification function ready\n",
      "This function will NOT modify your original files!\n"
     ]
    }
   ],
   "source": [
    "# Classification Function (Read-Only Safe)\n",
    "# ========================================\n",
    "\n",
    "def classify_audio_file(file_path, model, preserve_structure=True):\n",
    "    \"\"\"\n",
    "    Classify a single audio file and return prediction info\n",
    "    This function does NOT modify the original file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and process audio\n",
    "        waveform, samplerate = librosa.load(str(file_path), sr=44100, mono=True)\n",
    "        waveform = librosa.util.fix_length(waveform, size=50000)\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfcc = librosa.feature.mfcc(y=waveform, sr=samplerate, n_mfcc=40, n_fft=2048, hop_length=512)\n",
    "        features = librosa.util.normalize(mfcc)\n",
    "        features = features[np.newaxis, ...]\n",
    "        \n",
    "        # Predict\n",
    "        probs = model.predict(features, verbose=0)\n",
    "        label = np.argmax(probs)\n",
    "        confidence = np.max(probs)\n",
    "        \n",
    "        # Map to instrument names\n",
    "        instrument_names = [\"Crash\", \"Hihat\", \"Kick\", \"Ride\", \"Snare\", \"Tom\"]\n",
    "        predicted_instrument = instrument_names[label]\n",
    "        \n",
    "        # Generate output filename preserving original structure\n",
    "        file_path = Path(file_path)\n",
    "        if preserve_structure:\n",
    "            # Keep relative path structure in filename\n",
    "            relative_path = file_path.relative_to(ARCHIVE_PATH)\n",
    "            safe_path = str(relative_path).replace('/', '_').replace('\\\\', '_')\n",
    "            output_filename = f\"{predicted_instrument.lower()}_{confidence:.3f}_{safe_path}\"\n",
    "        else:\n",
    "            output_filename = f\"{predicted_instrument.lower()}_{confidence:.3f}_{file_path.name}\"\n",
    "        \n",
    "        return {\n",
    "            'original_path': str(file_path),\n",
    "            'predicted_class': predicted_instrument,\n",
    "            'confidence': confidence,\n",
    "            'output_filename': output_filename,\n",
    "            'success': True,\n",
    "            'error': None\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'original_path': str(file_path),\n",
    "            'predicted_class': None,\n",
    "            'confidence': 0.0,\n",
    "            'output_filename': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"\u2705 Classification function ready\")\n",
    "print(\"This function will NOT modify your original files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b72e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save Processing Metadata (For Repeat Runs)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# ===========================================\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create processing report\u001b[39;00m\n\u001b[32m      5\u001b[39m report = {\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m: datetime.now().isoformat(),\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33marchive_path\u001b[39m\u001b[33m'\u001b[39m: ARCHIVE_PATH,\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33moutput_path\u001b[39m\u001b[33m'\u001b[39m: OUTPUT_PATH,\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtotal_files_found\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(audio_files),\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfiles_processed\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(\u001b[43mresults\u001b[49m),\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msuccessful_classifications\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(successful),\n\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33merrors\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(errors),\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mprocessing_mode\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m COPY_FILES \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33msymlink\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mclass_distribution\u001b[39m\u001b[33m'\u001b[39m: class_counts \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mclass_counts\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m() \u001b[38;5;28;01melse\u001b[39;00m {},\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mconfiguration\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     16\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmax_files_per_run\u001b[39m\u001b[33m'\u001b[39m: MAX_FILES_PER_RUN,\n\u001b[32m     17\u001b[39m         \u001b[33m'\u001b[39m\u001b[33msupported_formats\u001b[39m\u001b[33m'\u001b[39m: SUPPORTED_FORMATS,\n\u001b[32m     18\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel_shape\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(model.input_shape) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     19\u001b[39m     }\n\u001b[32m     20\u001b[39m }\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Save detailed results\u001b[39;00m\n\u001b[32m     23\u001b[39m report_file = Path(OUTPUT_PATH) / \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mclassification_report_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m_\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Save Processing Metadata (For Repeat Runs)\n",
    "# ===========================================\n",
    "\n",
    "\n",
    "# Only save report if results exist (i.e., processing was run)\n",
    "if 'results' in locals() and results is not None:\n",
    "    # Create processing report\n",
    "    report = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'archive_path': ARCHIVE_PATH,\n",
    "        'output_path': OUTPUT_PATH,\n",
    "        'total_files_found': len(audio_files),\n",
    "        'files_processed': len(results),\n",
    "        'successful_classifications': len(successful),\n",
    "        'errors': len(errors),\n",
    "        'processing_mode': 'copy' if COPY_FILES else 'symlink',\n",
    "        'class_distribution': class_counts if 'class_counts' in locals() else {},\n",
    "        'configuration': {\n",
    "            'max_files_per_run': MAX_FILES_PER_RUN,\n",
    "            'supported_formats': SUPPORTED_FORMATS,\n",
    "            'model_shape': str(model.input_shape) if 'model' in locals() else None\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save detailed results\n",
    "    report_file = Path(OUTPUT_PATH) / \"metadata\" / f\"classification_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(report_file, 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "\n",
    "    # Save detailed file results\n",
    "    if results:\n",
    "        detailed_file = Path(OUTPUT_PATH) / \"metadata\" / f\"detailed_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(detailed_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "    print(f\"\ud83d\udcc4 Processing report saved: {report_file}\")\n",
    "    print(f\"\ud83d\udcc4 Detailed results saved: {detailed_file}\")\n",
    "\n",
    "    # Show quick stats for rerun reference\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"\ud83d\udccb SUMMARY FOR FUTURE REFERENCE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Archive scanned: {ARCHIVE_PATH}\")\n",
    "    print(f\"Output directory: {OUTPUT_PATH}\")\n",
    "    print(f\"Files in archive: {len(audio_files)}\")\n",
    "    print(f\"Successfully classified: {len(successful)}\")\n",
    "    print(f\"Mode: {'File copies' if COPY_FILES else 'Symbolic links'}\")\n",
    "    print(\"\\nTo rerun classification:\")\n",
    "    print(\"1. Simply run all cells again\")\n",
    "    print(\"2. Adjust MAX_FILES_PER_RUN to process different batches\")\n",
    "    print(\"3. Change COPY_FILES to switch between copy/symlink modes\")\n",
    "    print(\"4. Your original archive will always remain untouched!\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f No results to save. Please run the processing cell above first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}