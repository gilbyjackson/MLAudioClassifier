{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Classification & Archive Generation\n",
    "\n",
    "## 8. Label Mapping Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create label mapping\n",
    "label_mapping_path = PATHS['models'] / 'label_mapping.json'\n",
    "canonical_mapping_path = PATHS['models'] / 'canonical_mapping.json'\n",
    "\n",
    "def load_label_mapping(path: Path, model_output_dim: int) -> List[str]:\n",
    "    \"\"\"Load label mapping with fallback to generic labels.\"\"\"\n",
    "    if path.exists():\n",
    "        with open(path, 'r') as f:\n",
    "            labels = json.load(f)\n",
    "        if len(labels) == model_output_dim:\n",
    "            return labels\n",
    "        else:\n",
    "            print(f\"⚠️  Label count mismatch: {len(labels)} vs {model_output_dim}\")\n",
    "    \n",
    "    # Fallback to generic\n",
    "    print(f\"⚠️  Using generic labels\")\n",
    "    return [f\"class_{i}\" for i in range(model_output_dim)]\n",
    "\n",
    "def load_canonical_mapping(path: Path) -> Dict[str, str]:\n",
    "    \"\"\"Load canonical mapping (34 classes → 6 core drums).\"\"\"\n",
    "    if path.exists():\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "# Load mappings\n",
    "if 'model1' in models_dict:\n",
    "    model_dim = models_dict['model1'].output_shape[-1]\n",
    "    LABELS = load_label_mapping(label_mapping_path, model_dim)\n",
    "    print(f\"✅ Loaded {len(LABELS)} labels\")\n",
    "    print(f\"   Sample: {LABELS[:6]}\")\n",
    "else:\n",
    "    LABELS = TARGET_LABELS\n",
    "    print(f\"✅ Using default target labels: {LABELS}\")\n",
    "\n",
    "CANONICAL_MAP = load_canonical_mapping(canonical_mapping_path)\n",
    "if CANONICAL_MAP:\n",
    "    print(f\"✅ Loaded canonical mapping: {len(CANONICAL_MAP)} entries\")\n",
    "else:\n",
    "    print(f\"⚠️  No canonical mapping found, using direct labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Archive Classification (Production)\n",
    "\n",
    "Batch classify audio archive using trained model with production-grade features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification helper functions\n",
    "def hash_file(path: Path, algorithm: str = 'md5') -> str:\n",
    "    \"\"\"Compute file hash for deduplication.\"\"\"\n",
    "    hasher = hashlib.md5() if algorithm == 'md5' else hashlib.sha256()\n",
    "    with open(path, 'rb') as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b''):\n",
    "            hasher.update(chunk)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def discover_audio_files(root: Path, extensions: List[str] = None) -> List[Path]:\n",
    "    \"\"\"Recursively discover audio files.\"\"\"\n",
    "    if extensions is None:\n",
    "        extensions = ['.wav', '.mp3', '.flac', '.aiff', '.aif']\n",
    "    \n",
    "    files = []\n",
    "    for ext in extensions:\n",
    "        files.extend(root.rglob(f'*{ext}'))\n",
    "    return sorted(files)\n",
    "\n",
    "def batch_tensorize(mfcc_list: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"Convert list of MFCC arrays to model input tensor.\"\"\"\n",
    "    return np.array(mfcc_list)\n",
    "\n",
    "def apply_canonical_mapping(label: str, mapping: Dict[str, str]) -> str:\n",
    "    \"\"\"Map fine-grained label to canonical class.\"\"\"\n",
    "    return mapping.get(label, label)\n",
    "\n",
    "print(\"✅ Classification helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure classification run\n",
    "ARCHIVE_PATH = PATHS['archive']  # Source directory\n",
    "RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "RUN_OUTPUT_DIR = PATHS['classified'] / f'run_{RUN_TIMESTAMP}'\n",
    "RUN_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Classification Configuration:\")\n",
    "print(f\"  Source: {ARCHIVE_PATH}\")\n",
    "print(f\"  Output: {RUN_OUTPUT_DIR}\")\n",
    "print(f\"  Batch size: {CLASSIFICATION_CONFIG['batch_size']}\")\n",
    "print(f\"  Confidence threshold: {CLASSIFICATION_CONFIG['confidence_threshold']}\")\n",
    "print(f\"  Deduplication: {CLASSIFICATION_CONFIG['dedup_hash']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover files to classify\n",
    "print(f\"\\nDiscovering audio files in: {ARCHIVE_PATH}\")\n",
    "audio_files = discover_audio_files(ARCHIVE_PATH)\n",
    "print(f\"✅ Found {len(audio_files):,} audio files\")\n",
    "\n",
    "if len(audio_files) == 0:\n",
    "    print(\"⚠️  No audio files found. Check ARCHIVE_PATH.\")\n",
    "else:\n",
    "    print(f\"   Sample files:\")\n",
    "    for f in audio_files[:5]:\n",
    "        print(f\"     - {f.relative_to(ARCHIVE_PATH)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch classification\n",
    "if len(audio_files) > 0 and 'model1' in models_dict:\n",
    "    model = models_dict['model1']\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Running Archive Classification\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    results_list = []\n",
    "    errors = []\n",
    "    seen_hashes = set()\n",
    "    duplicate_count = 0\n",
    "    \n",
    "    # Process in batches\n",
    "    batch_size = CLASSIFICATION_CONFIG['batch_size']\n",
    "    \n",
    "    for i in tqdm(range(0, len(audio_files), batch_size), desc=\"Classifying batches\"):\n",
    "        batch_files = audio_files[i:i+batch_size]\n",
    "        \n",
    "        # Extract features for batch\n",
    "        batch_mfccs = []\n",
    "        batch_valid_files = []\n",
    "        \n",
    "        for file_path in batch_files:\n",
    "            # Check for duplicates\n",
    "            if CLASSIFICATION_CONFIG['dedup_hash']:\n",
    "                file_hash = hash_file(file_path, CLASSIFICATION_CONFIG['hash_algorithm'])\n",
    "                if file_hash in seen_hashes:\n",
    "                    duplicate_count += 1\n",
    "                    continue\n",
    "                seen_hashes.add(file_hash)\n",
    "            \n",
    "            # Extract MFCC\n",
    "            mfcc, metadata = extract_mfcc(file_path, AUDIO_CONFIG)\n",
    "            \n",
    "            if mfcc is not None:\n",
    "                batch_mfccs.append(mfcc)\n",
    "                batch_valid_files.append(file_path)\n",
    "            else:\n",
    "                errors.append({\n",
    "                    'file': str(file_path),\n",
    "                    'error': metadata['error']\n",
    "                })\n",
    "        \n",
    "        if len(batch_mfccs) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Predict\n",
    "        X_batch = batch_tensorize(batch_mfccs)\n",
    "        predictions = model.predict(X_batch, verbose=0)\n",
    "        \n",
    "        # Process predictions\n",
    "        for file_path, probs in zip(batch_valid_files, predictions):\n",
    "            pred_idx = np.argmax(probs)\n",
    "            confidence = float(probs[pred_idx])\n",
    "            pred_label = LABELS[pred_idx]\n",
    "            \n",
    "            # Apply canonical mapping\n",
    "            canonical_label = apply_canonical_mapping(pred_label, CANONICAL_MAP)\n",
    "            \n",
    "            # Determine final label (with misc routing)\n",
    "            if canonical_label not in TARGET_LABELS:\n",
    "                final_label = 'misc'\n",
    "                reason = 'not_in_target'\n",
    "            elif confidence < CLASSIFICATION_CONFIG['confidence_threshold']:\n",
    "                final_label = 'misc'\n",
    "                reason = 'low_confidence'\n",
    "            else:\n",
    "                final_label = canonical_label\n",
    "                reason = 'accepted'\n",
    "            \n",
    "            # Store result\n",
    "            results_list.append({\n",
    "                'file': str(file_path.relative_to(ARCHIVE_PATH)),\n",
    "                'pred_label': pred_label,\n",
    "                'canonical_label': canonical_label,\n",
    "                'final_label': final_label,\n",
    "                'confidence': confidence,\n",
    "                'reason': reason,\n",
    "                'top_k': {LABELS[idx]: float(probs[idx]) \n",
    "                         for idx in np.argsort(probs)[-CLASSIFICATION_CONFIG['top_k']:][::-1]}\n",
    "            })\n",
    "    \n",
    "    print(f\"\\n✅ Classification complete\")\n",
    "    print(f\"   Processed: {len(results_list):,} files\")\n",
    "    print(f\"   Duplicates skipped: {duplicate_count:,}\")\n",
    "    print(f\"   Errors: {len(errors)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️  Skipping classification - no files or model not available\")\n",
    "    results_list = []\n",
    "    errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classification results\n",
    "if results_list:\n",
    "    # Save detailed results\n",
    "    results_path = RUN_OUTPUT_DIR / 'classification_results.json'\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results_list, f, indent=2)\n",
    "    print(f\"✅ Results saved: {results_path}\")\n",
    "    \n",
    "    # Save errors if any\n",
    "    if errors:\n",
    "        errors_path = RUN_OUTPUT_DIR / 'errors.json'\n",
    "        with open(errors_path, 'w') as f:\n",
    "            json.dump(errors, f, indent=2)\n",
    "        print(f\"✅ Errors saved: {errors_path}\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary = {\n",
    "        'timestamp': RUN_TIMESTAMP,\n",
    "        'source': str(ARCHIVE_PATH),\n",
    "        'total_files': len(audio_files),\n",
    "        'processed': len(results_list),\n",
    "        'errors': len(errors),\n",
    "        'config': CLASSIFICATION_CONFIG,\n",
    "        'label_distribution': {}\n",
    "    }\n",
    "    \n",
    "    # Calculate distribution\n",
    "    from collections import Counter\n",
    "    dist = Counter([r['final_label'] for r in results_list])\n",
    "    summary['label_distribution'] = dict(dist)\n",
    "    \n",
    "    summary_path = RUN_OUTPUT_DIR / 'summary.json'\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"✅ Summary saved: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Archive Regeneration & Organization\n",
    "\n",
    "Materialize organized archive from classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure regeneration\n",
    "REGENERATED_OUTPUT = PATHS['classified'] / f'Organized_{RUN_TIMESTAMP}'\n",
    "COPY_MODE = 'copy'  # 'copy', 'symlink', or 'none'\n",
    "\n",
    "print(f\"Regeneration Configuration:\")\n",
    "print(f\"  Input results: {RUN_OUTPUT_DIR}\")\n",
    "print(f\"  Output directory: {REGENERATED_OUTPUT}\")\n",
    "print(f\"  Copy mode: {COPY_MODE}\")\n",
    "print(f\"  Target labels: {', '.join(TARGET_LABELS + ['misc'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate organized archive\n",
    "if results_list and COPY_MODE != 'none':\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Regenerating Organized Archive\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Create output directories\n",
    "    for label in TARGET_LABELS + ['misc']:\n",
    "        (REGENERATED_OUTPUT / label).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create manifests directory\n",
    "    manifests_dir = REGENERATED_OUTPUT / '_manifests'\n",
    "    manifests_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Copy files to organized structure\n",
    "    manifests = {label: [] for label in TARGET_LABELS + ['misc']}\n",
    "    copy_count = 0\n",
    "    \n",
    "    for result in tqdm(results_list, desc=\"Organizing files\"):\n",
    "        src_file = ARCHIVE_PATH / result['file']\n",
    "        final_label = result['final_label']\n",
    "        \n",
    "        if not src_file.exists():\n",
    "            continue\n",
    "        \n",
    "        # Destination\n",
    "        dst_file = REGENERATED_OUTPUT / final_label / src_file.name\n",
    "        \n",
    "        # Handle name collisions\n",
    "        if dst_file.exists():\n",
    "            stem = dst_file.stem\n",
    "            suffix = dst_file.suffix\n",
    "            counter = 1\n",
    "            while dst_file.exists():\n",
    "                dst_file = REGENERATED_OUTPUT / final_label / f\"{stem}_{counter}{suffix}\"\n",
    "                counter += 1\n",
    "        \n",
    "        # Copy or symlink\n",
    "        try:\n",
    "            if COPY_MODE == 'copy':\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "            elif COPY_MODE == 'symlink':\n",
    "                dst_file.symlink_to(src_file.absolute())\n",
    "            \n",
    "            manifests[final_label].append({\n",
    "                'original': str(result['file']),\n",
    "                'confidence': result['confidence'],\n",
    "                'pred_label': result['pred_label']\n",
    "            })\n",
    "            copy_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {src_file}: {e}\")\n",
    "    \n",
    "    # Save manifests\n",
    "    for label, items in manifests.items():\n",
    "        if items:\n",
    "            manifest_path = manifests_dir / f\"{label}.json\"\n",
    "            with open(manifest_path, 'w') as f:\n",
    "                json.dump(items, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n✅ Archive regeneration complete\")\n",
    "    print(f\"   Files organized: {copy_count:,}\")\n",
    "    print(f\"   Output: {REGENERATED_OUTPUT}\")\n",
    "    \n",
    "    # Print distribution\n",
    "    print(f\"\\n   Distribution:\")\n",
    "    for label in TARGET_LABELS + ['misc']:\n",
    "        count = len(manifests[label])\n",
    "        if count > 0:\n",
    "            print(f\"     {label:10s}: {count:5,} files\")\n",
    "\n",
    "elif COPY_MODE == 'none':\n",
    "    print(\"⚠️  COPY_MODE='none' - skipping materialization\")\n",
    "else:\n",
    "    print(\"⚠️  No results to regenerate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Statistics & Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive statistics\n",
    "if results_list:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Classification Statistics\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Overall stats\n",
    "    confidences = [r['confidence'] for r in results_list]\n",
    "    print(f\"Confidence Statistics:\")\n",
    "    print(f\"  Mean: {np.mean(confidences):.4f}\")\n",
    "    print(f\"  Median: {np.median(confidences):.4f}\")\n",
    "    print(f\"  Std Dev: {np.std(confidences):.4f}\")\n",
    "    print(f\"  Min: {np.min(confidences):.4f}\")\n",
    "    print(f\"  Max: {np.max(confidences):.4f}\")\n",
    "    \n",
    "    # Label distribution\n",
    "    from collections import Counter\n",
    "    final_dist = Counter([r['final_label'] for r in results_list])\n",
    "    pred_dist = Counter([r['pred_label'] for r in results_list])\n",
    "    \n",
    "    print(f\"\\nFinal Label Distribution (after canonical mapping):\")\n",
    "    for label, count in sorted(final_dist.items(), key=lambda x: -x[1]):\n",
    "        pct = 100 * count / len(results_list)\n",
    "        print(f\"  {label:15s}: {count:6,} ({pct:5.2f}%)\")\n",
    "    \n",
    "    # Reason breakdown\n",
    "    reason_dist = Counter([r['reason'] for r in results_list])\n",
    "    print(f\"\\nRouting Reasons:\")\n",
    "    for reason, count in sorted(reason_dist.items(), key=lambda x: -x[1]):\n",
    "        pct = 100 * count / len(results_list)\n",
    "        print(f\"  {reason:20s}: {count:6,} ({pct:5.2f}%)\")\n",
    "    \n",
    "    # Visualize distribution\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Confidence distribution\n",
    "    ax1.hist(confidences, bins=50, color='steelblue', edgecolor='black')\n",
    "    ax1.axvline(CLASSIFICATION_CONFIG['confidence_threshold'], \n",
    "                color='red', linestyle='--', label='Threshold')\n",
    "    ax1.set_xlabel('Confidence')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title('Confidence Distribution')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Label distribution\n",
    "    labels = list(final_dist.keys())\n",
    "    counts = [final_dist[l] for l in labels]\n",
    "    ax2.bar(labels, counts, color='steelblue', edgecolor='black')\n",
    "    ax2.set_xlabel('Label')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Final Label Distribution')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RUN_OUTPUT_DIR / 'statistics.png', dpi=120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✅ Statistics plot saved: {RUN_OUTPUT_DIR / 'statistics.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🎉 All-in-One Pipeline Complete!\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook has completed:\n",
    "\n",
    "### ✅ Part 1: ML Development\n",
    "- Environment setup and configuration\n",
    "- MFCC feature extraction\n",
    "- Model 1 training (direct MFCC CNN)\n",
    "\n",
    "### ✅ Part 2: Model Evaluation  \n",
    "- Model loading and comparison\n",
    "- Performance metrics and visualizations\n",
    "- Confusion matrices and classification reports\n",
    "\n",
    "### ✅ Part 3: Classification & Archive\n",
    "- Label mapping validation\n",
    "- Production archive classification\n",
    "- Archive regeneration and organization\n",
    "- Comprehensive statistics and reporting\n",
    "\n",
    "## 📁 Output Locations\n",
    "\n",
    "- **Models**: `models/model1.keras`, `models/model1_history.json`\n",
    "- **Results**: `results/` (training plots, confusion matrices)\n",
    "- **Classification**: `ClassifiedArchive/run_<timestamp>/`\n",
    "- **Organized Archive**: `ClassifiedArchive/Organized_<timestamp>/`\n",
    "\n",
    "## 🚀 Next Steps\n",
    "\n",
    "- Review classification results in the output directories\n",
    "- Adjust confidence threshold if needed and re-run Part 3\n",
    "- Train Model 2 using the dedicated Model2_Train.ipynb for comparison\n",
    "- Use the CLI for faster batch processing: `python -m classifier.cli`\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
