{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae08352",
   "metadata": {},
   "source": [
    "# Drum Sample Auto-Classifier\n",
    "\n",
    "This notebook demonstrates how to use the trained model to automatically classify and organize your unsorted drum samples.\n",
    "\n",
    "## Prerequisites\n",
    "1. **Train a model first** by running these notebooks in order:\n",
    "   - `MFCC_Feature_Extractor.ipynb` (extracts features from sorted training data)\n",
    "   - `Model1_Train.ipynb` or `Model2_Train.ipynb` (trains the classifier)\n",
    "\n",
    "2. **Prepare your unsorted data**:\n",
    "   - Create a folder called `complete_drum_archive` in your project directory\n",
    "   - Put all your unsorted `.wav` files in the `complete_drum_archive` folder\n",
    "\n",
    "## How it works\n",
    "- Loads your trained model (`models/model.keras`)\n",
    "- Processes each audio file in `complete_drum_archive`\n",
    "- Predicts which instrument it is (Crash, Hihat, Kick, Ride, Snare, Tom)\n",
    "- Moves files into organized folders with confidence scores\n",
    "- Files are renamed to include the predicted class and confidence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c89f76a-0384-425b-a534-e3c49e081b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import keras\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9763ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory: /Users/Gilby/Projects/MLAudioClassifier\n",
      "Archive source: complete_drum_archive\n",
      "Output destination: ClassifiedArchive\n",
      "Mode: COPY files\n",
      "Structure preservation: ON\n",
      "\n",
      "✅ Archive found at complete_drum_archive\n"
     ]
    }
   ],
   "source": [
    "# Configuration Paths\n",
    "# ===================\n",
    "\n",
    "# Project directory (where the trained model is located)\n",
    "PROJECT_PATH = \"/Users/Gilby/Projects/MLAudioClassifier\"\n",
    "\n",
    "# Archive directory (your complete drum archive with nested structure)\n",
    "ARCHIVE_PATH = \"complete_drum_archive\"  # Update this to your actual path\n",
    "OUTPUT_PATH = \"ClassifiedArchive\"  # Where organized files will be placed\n",
    "\n",
    "# Processing options\n",
    "COPY_FILES = True  # True = copy files (keeps originals), False = move files\n",
    "MAX_FILES_PER_RUN = None  # Limit files per run (None = process all)\n",
    "PRESERVE_STRUCTURE = True  # Preserve original folder structure in filenames\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Project directory: {PROJECT_PATH}\")\n",
    "print(f\"Archive source: {ARCHIVE_PATH}\")\n",
    "print(f\"Output destination: {OUTPUT_PATH}\")\n",
    "print(f\"Mode: {'COPY' if COPY_FILES else 'MOVE'} files\")\n",
    "print(f\"Structure preservation: {'ON' if PRESERVE_STRUCTURE else 'OFF'}\")\n",
    "\n",
    "# Verify archive exists\n",
    "if not os.path.exists(ARCHIVE_PATH):\n",
    "    print(f\"\\n❌ ERROR: Archive not found at {ARCHIVE_PATH}\")\n",
    "    print(\"Please update ARCHIVE_PATH to point to your complete_drum_archive\")\n",
    "else:\n",
    "    print(f\"\\n✅ Archive found at {ARCHIVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0877b4-5af0-477b-8efa-8346f8feaea3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=models/model.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model=\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodels/model.keras\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/MLAudioClassifier/.venv/lib/python3.13/site-packages/keras/src/saving/saving_api.py:203\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath,\n\u001b[32m    198\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    199\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    200\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    201\u001b[39m     )\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    204\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m     )\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    210\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    211\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmight have a different name).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    221\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=models/model.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('models/model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333493ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3920</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,007,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3920\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,007,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,155,525</span> (8.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,155,525\u001b[0m (8.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,155,523</span> (8.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,155,523\u001b[0m (8.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model expects input shape: (None, 40, 98)\n",
      "Model outputs 3 classes\n",
      "\n",
      "🔍 Scanning complete_drum_archive for audio files...\n",
      "❌ Archive not found at complete_drum_archive\n"
     ]
    }
   ],
   "source": [
    "# Verify model and scan archive\n",
    "print(\"Model Summary:\")\n",
    "model.summary()\n",
    "print(f\"\\nModel expects input shape: {model.input_shape}\")\n",
    "print(f\"Model outputs {model.output_shape[1]} classes\")\n",
    "\n",
    "# Scan archive for all .wav files (including nested directories)\n",
    "print(f\"\\n🔍 Scanning {ARCHIVE_PATH} for audio files...\")\n",
    "\n",
    "def find_wav_files(root_path):\n",
    "    \"\"\"Recursively find all .wav files and preserve their relative paths\"\"\"\n",
    "    wav_files = []\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.wav'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                # Calculate relative path from archive root\n",
    "                rel_path = os.path.relpath(full_path, root_path)\n",
    "                wav_files.append((full_path, rel_path))\n",
    "    return wav_files\n",
    "\n",
    "if os.path.exists(ARCHIVE_PATH):\n",
    "    all_wav_files = find_wav_files(ARCHIVE_PATH)\n",
    "    print(f\"✅ Found {len(all_wav_files)} .wav files in archive\")\n",
    "    \n",
    "    # Show directory structure summary \n",
    "    dirs = set()\n",
    "    for _, rel_path in all_wav_files:\n",
    "        dir_path = os.path.dirname(rel_path)\n",
    "        if dir_path:\n",
    "            dirs.add(dir_path)\n",
    "    \n",
    "    print(f\"📁 Archive contains {len(dirs)} directories with samples\")\n",
    "    if len(dirs) <= 10:  # Show directories if not too many\n",
    "        for directory in sorted(dirs):\n",
    "            count = sum(1 for _, rel_path in all_wav_files if rel_path.startswith(directory))\n",
    "            print(f\"   {directory}: {count} files\")\n",
    "    else:\n",
    "        print(\"   (Many nested directories - structure will be preserved)\")\n",
    "        \n",
    "    if MAX_FILES_PER_RUN and len(all_wav_files) > MAX_FILES_PER_RUN:\n",
    "        print(f\"\\n⚠️  Will process first {MAX_FILES_PER_RUN} files this run\")\n",
    "else:\n",
    "    print(f\"❌ Archive not found at {ARCHIVE_PATH}\")\n",
    "    all_wav_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d3a83-06f6-41a5-a8cb-41a4aec68f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ No audio files found to process!\n"
     ]
    }
   ],
   "source": [
    "# Process archive with nested structure preservation\n",
    "if not all_wav_files:\n",
    "    print(\"❌ No audio files found to process!\")\n",
    "else:\n",
    "    # Create output directory structure\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "        print(f\"📁 Created output directory: {OUTPUT_PATH}\")\n",
    "    \n",
    "    # Create instrument class folders\n",
    "    instrument_names = [\"Crash\", \"Hihat\", \"Kick\", \"Ride\", \"Snare\", \"Tom\"]\n",
    "    for instrument in instrument_names:\n",
    "        instrument_dir = os.path.join(OUTPUT_PATH, instrument)\n",
    "        if not os.path.exists(instrument_dir):\n",
    "            os.makedirs(instrument_dir)\n",
    "            print(f\"📁 Created {instrument} folder\")\n",
    "    \n",
    "    # Process files (limit if specified)\n",
    "    files_to_process = all_wav_files[:MAX_FILES_PER_RUN] if MAX_FILES_PER_RUN else all_wav_files\n",
    "    print(f\"\\n🎵 Processing {len(files_to_process)} audio files...\")\n",
    "    \n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    classification_stats = {name: 0 for name in instrument_names}\n",
    "    \n",
    "    for full_path, rel_path in files_to_process:\n",
    "        try:\n",
    "            print(f\"Processing: {rel_path}\")\n",
    "            \n",
    "            # Load and process the audio file\n",
    "            waveform, samplerate = librosa.load(full_path, sr=44100, mono=True)\n",
    "            waveform = librosa.util.fix_length(waveform, size=50000)\n",
    "            mfcc = librosa.feature.mfcc(y=waveform, sr=samplerate, n_mfcc=40, n_fft=2048, hop_length=512)\n",
    "            features = librosa.util.normalize(mfcc)\n",
    "            features = features[np.newaxis, ...]\n",
    "            \n",
    "            # Predict the instrument class\n",
    "            probs = model.predict(features, verbose=0)\n",
    "            label = np.argmax(probs)\n",
    "            confidence = np.max(probs)\n",
    "            predicted_instrument = instrument_names[label]\n",
    "            \n",
    "            # Create output filename preserving structure information\n",
    "            original_filename = os.path.basename(rel_path)\n",
    "            name_without_ext = os.path.splitext(original_filename)[0]\n",
    "            \n",
    "            if PRESERVE_STRUCTURE:\n",
    "                # Include directory structure in filename\n",
    "                dir_structure = os.path.dirname(rel_path).replace('/', '_').replace('\\\\', '_')\n",
    "                if dir_structure:\n",
    "                    new_filename = f\"{predicted_instrument.lower()}_{confidence:.3f}_{dir_structure}_{name_without_ext}.wav\"\n",
    "                else:\n",
    "                    new_filename = f\"{predicted_instrument.lower()}_{confidence:.3f}_{name_without_ext}.wav\"\n",
    "            else:\n",
    "                new_filename = f\"{predicted_instrument.lower()}_{confidence:.3f}_{name_without_ext}.wav\"\n",
    "            \n",
    "            # Determine destination\n",
    "            destination_dir = os.path.join(OUTPUT_PATH, predicted_instrument)\n",
    "            destination_path = os.path.join(destination_dir, new_filename)\n",
    "            \n",
    "            # Copy or move file\n",
    "            if COPY_FILES:\n",
    "                shutil.copy2(full_path, destination_path)  # copy2 preserves metadata\n",
    "                action = \"copied\"\n",
    "            else:\n",
    "                shutil.move(full_path, destination_path)\n",
    "                action = \"moved\"\n",
    "            \n",
    "            print(f\"  → {action} to {predicted_instrument} (confidence: {confidence:.3f})\")\n",
    "            \n",
    "            processed_count += 1\n",
    "            classification_stats[predicted_instrument] += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  → Error processing {rel_path}: {str(e)}\")\n",
    "            error_count += 1\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n📊 Processing Complete!\")\n",
    "    print(f\"✅ Successfully processed: {processed_count} files\")\n",
    "    if error_count > 0:\n",
    "        print(f\"❌ Errors: {error_count} files\")\n",
    "    \n",
    "    print(f\"\\n🎯 Classification Results:\")\n",
    "    for instrument, count in classification_stats.items():\n",
    "        if count > 0:\n",
    "            percentage = (count / processed_count) * 100\n",
    "            print(f\"   {instrument}: {count} files ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n📁 Results saved to: {os.path.abspath(OUTPUT_PATH)}\")\n",
    "    \n",
    "    if MAX_FILES_PER_RUN and len(all_wav_files) > MAX_FILES_PER_RUN:\n",
    "        remaining = len(all_wav_files) - MAX_FILES_PER_RUN\n",
    "        print(f\"\\n⏳ {remaining} files remaining for future runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74221cd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocessed_count\u001b[49m > \u001b[32m0\u001b[39m:\n\u001b[32m      6\u001b[39m     timestamp = datetime.now().strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m_\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Create metadata directory\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'processed_count' is not defined"
     ]
    }
   ],
   "source": [
    "# Save detailed results and metadata\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "if processed_count > 0:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create metadata directory\n",
    "    metadata_dir = os.path.join(OUTPUT_PATH, \"metadata\")\n",
    "    if not os.path.exists(metadata_dir):\n",
    "        os.makedirs(metadata_dir)\n",
    "    \n",
    "    # Save processing summary\n",
    "    summary = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"archive_path\": ARCHIVE_PATH,\n",
    "        \"total_files_found\": len(all_wav_files),\n",
    "        \"files_processed\": processed_count,\n",
    "        \"files_with_errors\": error_count,\n",
    "        \"classification_results\": classification_stats,\n",
    "        \"processing_mode\": \"copy\" if COPY_FILES else \"move\",\n",
    "        \"structure_preserved\": PRESERVE_STRUCTURE\n",
    "    }\n",
    "    \n",
    "    summary_file = os.path.join(metadata_dir, f\"processing_summary_{timestamp}.json\")\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(f\"📄 Metadata saved to: {summary_file}\")\n",
    "    \n",
    "    # Also save to a general \"latest\" file for easy access\n",
    "    latest_file = os.path.join(metadata_dir, \"latest_run.json\")\n",
    "    with open(latest_file, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(\"✅ All processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bdc3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
