{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f9fdd5",
   "metadata": {},
   "source": [
    "# MFCC Feature Extractor \n",
    "\n",
    "This is stage 1 of the Method 1 pipeline, so this should be the first notebook you run after unzipping the data archives. \n",
    "\n",
    "**Updated to support 6 instrument classes**: Crash, Hihat, Kick, Ride, Snare, Tom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfa7a95f-5b29-4c34-a37b-bbc6bc6a1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from math import log, pi, exp, ceil\n",
    "import statistics as st\n",
    "import pandas as pd\n",
    "import scipy.io as io\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "354a3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please set this variable to where you cloned the git repo \"MLAudioClassifier\"\n",
    "\n",
    "filepath = \"/Users/Gilby/Projects/MLAudioClassifier\"\n",
    "os.chdir(filepath)\n",
    "\n",
    "# make sure you have extracted the Training and Testing Data before you proceed with the rest of the notebook\n",
    "# with something like \"unzip TrainingData.zip\"\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caed6611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reset to project directory: /Users/Gilby/Projects/MLAudioClassifier\n",
      "✅ Found TrainingData/\n",
      "✅ Found TestData/\n",
      "Ready to proceed!\n"
     ]
    }
   ],
   "source": [
    "# Reset to project root directory (run this if you get lost in subdirectories)\n",
    "filepath = \"/Users/Gilby/Projects/MLAudioClassifier\"\n",
    "os.chdir(filepath)\n",
    "print(f\"✅ Reset to project directory: {os.getcwd()}\")\n",
    "\n",
    "# Verify we can see the expected directories\n",
    "expected_dirs = [\"TrainingData\", \"TestData\"]\n",
    "for directory in expected_dirs:\n",
    "    if os.path.exists(directory):\n",
    "        print(f\"✅ Found {directory}/\")\n",
    "    else:\n",
    "        print(f\"❌ Missing {directory}/\")\n",
    "        \n",
    "print(\"Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55792a",
   "metadata": {},
   "source": [
    "# Loading training data \n",
    "\n",
    "This block of code will load in each audio file of the training data set and calculate it's MFCCs for all 6 instrument classes (Crash, Hihat, Kick, Ride, Snare, Tom). Please note that there will be a lot of warnings in red after you run this cell, but they are just warnings and the code is still running fine without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "897b3fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking directory structure...\n",
      "Current directory: /Users/Gilby/Projects/MLAudioClassifier\n",
      "✅ Found TrainingData/AudioSamples\n",
      "   Training classes: ['Kick', 'Sizzle', 'Rim', 'Splash', 'Tom', 'Shaker', 'Bongo', 'Conga', 'Maracas', 'Metal', 'Hihat', 'Snare', 'Perc', 'FX', 'Ride', 'Agogo', 'Triangle', 'Whistle', 'Crash', 'Bass', 'Reverse', 'China', 'Tambourine', 'Vox', 'Noise', 'Clap', 'Woodblock', 'Clave', 'Cymbal', 'Bell', 'Cowbell', 'Cabasa', 'Vibraslap', 'Guiro', 'Timpani', 'Cuica', 'Timbale']\n",
      "   Kick: 1360 samples\n",
      "   Sizzle: 3 samples\n",
      "   Rim: 192 samples\n",
      "   Splash: 23 samples\n",
      "   Tom: 1828 samples\n",
      "   Shaker: 54 samples\n",
      "   Bongo: 151 samples\n",
      "   Conga: 335 samples\n",
      "   Maracas: 46 samples\n",
      "   Metal: 23 samples\n",
      "   Hihat: 969 samples\n",
      "   Snare: 2264 samples\n",
      "   Perc: 483 samples\n",
      "   FX: 1595 samples\n",
      "   Ride: 312 samples\n",
      "   Agogo: 52 samples\n",
      "   Triangle: 53 samples\n",
      "   Whistle: 40 samples\n",
      "   Crash: 187 samples\n",
      "   Bass: 107 samples\n",
      "   Reverse: 76 samples\n",
      "   China: 33 samples\n",
      "   Tambourine: 56 samples\n",
      "   Vox: 101 samples\n",
      "   Noise: 90 samples\n",
      "   Clap: 310 samples\n",
      "   Woodblock: 38 samples\n",
      "   Clave: 43 samples\n",
      "   Cymbal: 128 samples\n",
      "   Bell: 220 samples\n",
      "   Cowbell: 39 samples\n",
      "   Cabasa: 44 samples\n",
      "   Vibraslap: 12 samples\n",
      "   Guiro: 49 samples\n",
      "   Timpani: 23 samples\n",
      "   Cuica: 40 samples\n",
      "   Timbale: 86 samples\n",
      "✅ Found TestData\n",
      "   Test classes: ['Kick', 'Rim', 'Splash', 'Tom', 'Shaker', 'Bongo', 'Conga', 'Maracas', 'Metal', 'Hihat', 'Snare', 'Perc', 'Ride', 'Agogo', 'Triangle', 'Whistle', 'Crash', 'Bass', 'China', 'Tambourine', 'Clap', 'Woodblock', 'Clave', 'Bell', 'Cowbell', 'Cabasa', 'Guiro', 'Timpani', 'Cuica', 'Timbale']\n",
      "   Kick: 100 samples\n",
      "   Rim: 31 samples\n",
      "   Splash: 4 samples\n",
      "   Tom: 100 samples\n",
      "   Shaker: 10 samples\n",
      "   Bongo: 24 samples\n",
      "   Conga: 52 samples\n",
      "   Maracas: 9 samples\n",
      "   Metal: 4 samples\n",
      "   Hihat: 37 samples\n",
      "   Snare: 100 samples\n",
      "   Perc: 96 samples\n",
      "   Ride: 30 samples\n",
      "   Agogo: 9 samples\n",
      "   Triangle: 9 samples\n",
      "   Whistle: 7 samples\n",
      "   Crash: 35 samples\n",
      "   Bass: 13 samples\n",
      "   China: 6 samples\n",
      "   Tambourine: 11 samples\n",
      "   Clap: 57 samples\n",
      "   Woodblock: 6 samples\n",
      "   Clave: 8 samples\n",
      "   Bell: 15 samples\n",
      "   Cowbell: 7 samples\n",
      "   Cabasa: 8 samples\n",
      "   Guiro: 8 samples\n",
      "   Timpani: 4 samples\n",
      "   Cuica: 7 samples\n",
      "   Timbale: 16 samples\n",
      "\n",
      "Ready to process audio files!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify directory structure before processing\n",
    "# First, ensure we're in the correct project directory\n",
    "os.chdir(filepath)\n",
    "print(\"Checking directory structure...\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check training data\n",
    "train_path = \"TrainingData/AudioSamples\"\n",
    "if os.path.exists(train_path):\n",
    "    print(f\"✅ Found {train_path}\")\n",
    "    train_folders = [f for f in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, f)) and not f.startswith('.')]\n",
    "    print(f\"   Training classes: {train_folders}\")\n",
    "    for folder in train_folders:\n",
    "        wav_count = len(glob.glob(os.path.join(train_path, folder, \"*.wav\")))\n",
    "        print(f\"   {folder}: {wav_count} samples\")\n",
    "else:\n",
    "    print(f\"❌ {train_path} not found!\")\n",
    "\n",
    "# Check test data  \n",
    "test_path = \"TestData\"\n",
    "if os.path.exists(test_path):\n",
    "    print(f\"✅ Found {test_path}\")\n",
    "    test_folders = [f for f in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, f)) and not f.startswith('.')]\n",
    "    print(f\"   Test classes: {test_folders}\")\n",
    "    for folder in test_folders:\n",
    "        wav_count = len(glob.glob(os.path.join(test_path, folder, \"*.wav\")))\n",
    "        print(f\"   {folder}: {wav_count} samples\")\n",
    "else:\n",
    "    print(f\"❌ {test_path} not found!\")\n",
    "\n",
    "print(\"\\nReady to process audio files!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd85484d-d4b4-4738-97c2-4753d82d09fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from: /Users/Gilby/Projects/MLAudioClassifier\n",
      "Processing Kick samples...\n",
      "  Found 1360 files\n",
      "Processing Sizzle samples...\n",
      "  Found 3 files\n",
      "Processing Rim samples...\n",
      "  Found 192 files\n",
      "Processing Splash samples...\n",
      "  Found 23 files\n",
      "Processing Tom samples...\n",
      "  Found 1828 files\n",
      "Processing Shaker samples...\n",
      "  Found 54 files\n",
      "Processing Bongo samples...\n",
      "  Found 151 files\n",
      "Processing Conga samples...\n",
      "  Found 335 files\n",
      "Processing Maracas samples...\n",
      "  Found 46 files\n",
      "Processing Metal samples...\n",
      "  Found 23 files\n",
      "Processing Hihat samples...\n",
      "  Found 969 files\n",
      "Processing Snare samples...\n",
      "  Found 2264 files\n",
      "Processing Perc samples...\n",
      "  Found 483 files\n",
      "Processing FX samples...\n",
      "  Found 1595 files\n",
      "Processing Ride samples...\n",
      "  Found 312 files\n",
      "Processing Agogo samples...\n",
      "  Found 52 files\n",
      "Processing Triangle samples...\n",
      "  Found 53 files\n",
      "Processing Whistle samples...\n",
      "  Found 40 files\n",
      "Processing Crash samples...\n",
      "  Found 187 files\n",
      "Processing Bass samples...\n",
      "  Found 107 files\n",
      "Processing Reverse samples...\n",
      "  Found 76 files\n",
      "Processing China samples...\n",
      "  Found 33 files\n",
      "Processing Tambourine samples...\n",
      "  Found 56 files\n",
      "Processing Vox samples...\n",
      "  Found 101 files\n",
      "Processing Noise samples...\n",
      "  Found 90 files\n",
      "Processing Clap samples...\n",
      "  Found 310 files\n",
      "Processing Woodblock samples...\n",
      "  Found 38 files\n",
      "Processing Clave samples...\n",
      "  Found 43 files\n",
      "Processing Cymbal samples...\n",
      "  Found 128 files\n",
      "Processing Bell samples...\n",
      "  Found 220 files\n",
      "Processing Cowbell samples...\n",
      "  Found 39 files\n",
      "Processing Cabasa samples...\n",
      "  Found 44 files\n",
      "Processing Vibraslap samples...\n",
      "  Found 12 files\n",
      "Processing Guiro samples...\n",
      "  Found 49 files\n",
      "Processing Timpani samples...\n",
      "  Found 23 files\n",
      "Processing Cuica samples...\n",
      "  Found 40 files\n",
      "Processing Timbale samples...\n",
      "  Found 86 files\n",
      "Training data extraction complete!\n",
      "Total samples: 11465\n",
      "Class distribution: {np.int64(0): np.int64(1360), np.int64(1): np.int64(3), np.int64(2): np.int64(192), np.int64(3): np.int64(23), np.int64(4): np.int64(1828), np.int64(5): np.int64(54), np.int64(6): np.int64(151), np.int64(7): np.int64(335), np.int64(8): np.int64(46), np.int64(9): np.int64(23), np.int64(10): np.int64(969), np.int64(11): np.int64(2264), np.int64(12): np.int64(483), np.int64(13): np.int64(1595), np.int64(14): np.int64(312), np.int64(15): np.int64(52), np.int64(16): np.int64(53), np.int64(17): np.int64(40), np.int64(18): np.int64(187), np.int64(19): np.int64(107), np.int64(20): np.int64(76), np.int64(21): np.int64(33), np.int64(22): np.int64(56), np.int64(23): np.int64(101), np.int64(24): np.int64(90), np.int64(25): np.int64(310), np.int64(26): np.int64(38), np.int64(27): np.int64(43), np.int64(28): np.int64(128), np.int64(29): np.int64(220), np.int64(30): np.int64(39), np.int64(31): np.int64(44), np.int64(32): np.int64(12), np.int64(33): np.int64(49), np.int64(34): np.int64(23), np.int64(35): np.int64(40), np.int64(36): np.int64(86)}\n"
     ]
    }
   ],
   "source": [
    "# Ensure we're in the project root directory first\n",
    "os.chdir(filepath)\n",
    "print(f\"Starting from: {os.getcwd()}\")\n",
    "\n",
    "os.chdir(\"TrainingData/AudioSamples\")\n",
    "folder_names = glob.glob(\"*\")\n",
    "# Filter out hidden files and directories\n",
    "folder_names = [f for f in folder_names if not f.startswith('.') and os.path.isdir(f)]\n",
    "all_samples = { 'label':[], 'mfcc':[] }\n",
    "i=0\n",
    "frames_max = 0\n",
    "for instrument in folder_names:\n",
    "    print(f\"Processing {instrument} samples...\")\n",
    "    os.chdir(instrument)\n",
    "    file_names = glob.glob(\"*.wav\")\n",
    "    print(f\"  Found {len(file_names)} files\")\n",
    "    for wav in file_names:\n",
    "        waveform, samplerate = librosa.load(wav, sr=44100, mono=True)\n",
    "        waveform = librosa.util.fix_length(waveform, size=50000)\n",
    "        # Fixed: Added y= parameter for newer librosa versions\n",
    "        mfcc = librosa.feature.mfcc(y=waveform, sr=samplerate, n_mfcc=40, n_fft=2048, hop_length=512)\n",
    "        normalized_mfcc = librosa.util.normalize(mfcc)\n",
    "        all_samples['mfcc'].append(normalized_mfcc.tolist())\n",
    "        all_samples['label'].append(i)\n",
    "        # Update frames maximum\n",
    "        #if (num_frames > frames_max):\n",
    "            #frames_max = num_frames\n",
    "    os.chdir(\"..\")\n",
    "    i=i+1\n",
    "os.chdir(filepath)\n",
    "\n",
    "print(f\"Training data extraction complete!\")\n",
    "print(f\"Total samples: {len(all_samples['label'])}\")\n",
    "print(f\"Class distribution: {dict(zip(*np.unique(all_samples['label'], return_counts=True)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751cd3f3",
   "metadata": {},
   "source": [
    "<h1> Loading testing data </h1>\n",
    "<p> This block of code will load in each audio file of the testing data set and calculate it's MFCCs. Please note that there will be a lot of warnings in red after you run this cell, but they are just warnings and the code is still running fine without errors. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d3ae95-40c5-469f-949d-fb784193c5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Kick test samples...\n",
      "  Found 100 files\n",
      "Processing Rim test samples...\n",
      "  Found 31 files\n",
      "Processing Splash test samples...\n",
      "  Found 4 files\n",
      "Processing Tom test samples...\n",
      "  Found 100 files\n",
      "Processing Shaker test samples...\n",
      "  Found 10 files\n",
      "Processing Bongo test samples...\n",
      "  Found 24 files\n",
      "Processing Conga test samples...\n",
      "  Found 52 files\n",
      "Processing Maracas test samples...\n",
      "  Found 9 files\n",
      "Processing Metal test samples...\n",
      "  Found 4 files\n",
      "Processing Hihat test samples...\n",
      "  Found 37 files\n",
      "Processing Snare test samples...\n",
      "  Found 100 files\n",
      "Processing Perc test samples...\n",
      "  Found 96 files\n",
      "Processing Ride test samples...\n",
      "  Found 30 files\n",
      "Processing Agogo test samples...\n",
      "  Found 9 files\n",
      "Processing Triangle test samples...\n",
      "  Found 9 files\n",
      "Processing Whistle test samples...\n",
      "  Found 7 files\n",
      "Processing Crash test samples...\n",
      "  Found 35 files\n",
      "Processing Bass test samples...\n",
      "  Found 13 files\n",
      "Processing China test samples...\n",
      "  Found 6 files\n",
      "Processing Tambourine test samples...\n",
      "  Found 11 files\n",
      "Processing Clap test samples...\n",
      "  Found 57 files\n",
      "Processing Woodblock test samples...\n",
      "  Found 6 files\n",
      "Processing Clave test samples...\n",
      "  Found 8 files\n",
      "Processing Bell test samples...\n",
      "  Found 15 files\n",
      "Processing Cowbell test samples...\n",
      "  Found 7 files\n",
      "Processing Cabasa test samples...\n",
      "  Found 8 files\n",
      "Processing Guiro test samples...\n",
      "  Found 8 files\n",
      "Processing Timpani test samples...\n",
      "  Found 4 files\n",
      "Processing Cuica test samples...\n",
      "  Found 7 files\n",
      "Processing Timbale test samples...\n",
      "  Found 16 files\n",
      "Test data extraction complete!\n",
      "Total test samples: 823\n",
      "Test class distribution: {np.int64(0): np.int64(100), np.int64(1): np.int64(31), np.int64(2): np.int64(4), np.int64(3): np.int64(100), np.int64(4): np.int64(10), np.int64(5): np.int64(24), np.int64(6): np.int64(52), np.int64(7): np.int64(9), np.int64(8): np.int64(4), np.int64(9): np.int64(37), np.int64(10): np.int64(100), np.int64(11): np.int64(96), np.int64(12): np.int64(30), np.int64(13): np.int64(9), np.int64(14): np.int64(9), np.int64(15): np.int64(7), np.int64(16): np.int64(35), np.int64(17): np.int64(13), np.int64(18): np.int64(6), np.int64(19): np.int64(11), np.int64(20): np.int64(57), np.int64(21): np.int64(6), np.int64(22): np.int64(8), np.int64(23): np.int64(15), np.int64(24): np.int64(7), np.int64(25): np.int64(8), np.int64(26): np.int64(8), np.int64(27): np.int64(4), np.int64(28): np.int64(7), np.int64(29): np.int64(16)}\n"
     ]
    }
   ],
   "source": [
    "os.chdir(filepath)\n",
    "os.chdir(\"TestData\")  # Fixed: removed the extra /TestData\n",
    "folder_names = glob.glob(\"*\")\n",
    "# Filter out hidden files and directories\n",
    "folder_names = [f for f in folder_names if not f.startswith('.') and os.path.isdir(f)]\n",
    "test_samples = { 'label':[], 'mfcc':[] }\n",
    "i=0\n",
    "frames_max = 0\n",
    "for instrument in folder_names:\n",
    "    print(f\"Processing {instrument} test samples...\")\n",
    "    os.chdir(instrument)\n",
    "    file_names = glob.glob(\"*.wav\")\n",
    "    print(f\"  Found {len(file_names)} files\")\n",
    "    for wav in file_names:\n",
    "        waveform, samplerate = librosa.load(wav, sr=44100, mono=True)\n",
    "        waveform = librosa.util.fix_length(waveform, size=50000)\n",
    "        # Fixed: Added y= parameter for newer librosa versions\n",
    "        mfcc = librosa.feature.mfcc(y=waveform, sr=samplerate, n_mfcc=40, n_fft=2048, hop_length=512)\n",
    "        normalized_mfcc = librosa.util.normalize(mfcc)\n",
    "        test_samples['mfcc'].append(normalized_mfcc.tolist())\n",
    "        test_samples['label'].append(i)\n",
    "        # Update frames maximum\n",
    "        #if (num_frames > frames_max):\n",
    "            #frames_max = num_frames\n",
    "    os.chdir(\"..\")\n",
    "    i=i+1\n",
    "os.chdir(\"..\")\n",
    "\n",
    "print(f\"Test data extraction complete!\")\n",
    "print(f\"Total test samples: {len(test_samples['label'])}\")\n",
    "print(f\"Test class distribution: {dict(zip(*np.unique(test_samples['label'], return_counts=True)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab0b779a-403b-4758-a1be-2a251b7c78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(filepath)\n",
    "json_path='data/mfcc_train_data.json'\n",
    "with open(json_path, \"w\") as fp:\n",
    "        json.dump(all_samples, fp, indent=4)\n",
    "        \n",
    "json_path2='data/mfcc_test_data.json'\n",
    "with open(json_path2, \"w\") as fp2:\n",
    "        json.dump(test_samples, fp2, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
